# ============================================================================
# Experimental verification of Algorithm 2 (Schroeppel‚ÄìShamir variant)
# ============================================================================
#
# Purpose
# -------
# This Sage/Python script experimentally validates (a reduced-parameter version of)
# ‚ÄúAlgorithm 2‚Äù, which incorporates a Schroeppel‚ÄìShamir‚Äìstyle time‚Äìmemory trade-off
# into the PKP solving framework. In particular, the script performs:
#
#   1) Precomputation of Steinhaus‚ÄìJohnson‚ÄìTrotter (SJT) swap sequences for all
#      permutation blocks used in the two-level meet-in-the-middle decomposition.
#
#   2) Generation of a random PKP instance (A,b) over GF(q) together with a planted
#      solution vector whose coordinates are pairwise distinct.
#
#   3) Algebraic reduction of the augmented system to obtain the structured block
#      matrices and target vectors required by Algorithm 2.
#
#   4) Execution of the Schroeppel‚ÄìShamir two-stage meet-in-the-middle search:
#
#        ‚Ä¢ First-level collisions:
#            Construction of candidate list L‚ÇÅ via partial support enumeration
#            and incremental SJT updates.
#
#        ‚Ä¢ Second-level collisions:
#            Completion of supports, matching with L‚ÇÅ, filtering disjoint supports,
#            and reconstructing full candidate solutions.
#
#   5) Empirical measurement of:
#
#        ‚Ä¢ Raw collision counts at each level,
#        ‚Ä¢ Sizes of filtered candidate lists,
#        ‚Ä¢ expected number of repeatition of finding disjoint subsets that 
#          lie in the planted split,
#        ‚Ä¢ Average statistics over many independent trials.
#
#
# Notes
# -----
# ‚Ä¢ Parameters are fixed to small experimental values
#       (n = 20, m = 12, q = 47, etc.)
#   so that exhaustive enumeration and collision statistics remain feasible.
#
# ‚Ä¢ The implementation relies on:
#
#       ‚Äì Sage finite-field and linear-algebra primitives
#           (GF, random_matrix, rref, vector, matrix),
#
#       ‚Äì Steinhaus‚ÄìJohnson‚ÄìTrotter permutation ordering,
#           enabling incremental updates of linear forms after adjacent swaps,
#
#       ‚Äì A Schroeppel‚ÄìShamir decomposition of the support search space,
#           reducing memory usage while preserving correctness.
#
#
# ============================================================================


import random
import math
import numpy as np
import itertools
from collections import defaultdict
from functools import lru_cache
from sage.combinat.SJT import SJT


# ----------------------------------------------------------------------------
# Binomial coefficient 
# ----------------------------------------------------------------------------

@lru_cache(None)
def combination(n, k):
    """
    Binomial coefficient C(n, k) with caching.

    We cache to avoid recomputing combinatorial values repeatedly inside loops.
    """
    return int(math.comb(n, k))


# ----------------------------------------------------------------------------
# Steinhaus‚ÄìJohnson‚ÄìTrotter swap sequence
# ----------------------------------------------------------------------------

def compute_sjt_swap_sequence(n):
    """
    Precompute adjacent swap positions generated by the SJT order.

    The SJT algorithm enumerates permutations such that each next permutation
    differs from the previous by a single adjacent swap.

    Returns
    -------
    swap_positions : list[int]
        A list of length (n! - 1). Each entry is an index `idx` in {0,...,n-2}
        indicating that positions idx and idx+1 are swapped to get the next
        permutation in SJT order.

    ---------------------
    """
    swap_positions = []
    s = SJT(list(range(1, n + 1)))

    for _ in range(math.factorial(n) - 1):
        prev_perm = s._list[:]
        s = s.next()
        curr_perm = s._list[:]

        for idx in range(n - 1):
            if prev_perm[idx] != curr_perm[idx]:
                swap_positions.append(idx)
                break

    return swap_positions


# ============================================================================
# Fixed experimental parameters
# ============================================================================
# n  : number of variables / coordinates
# n1 : number of rows in the given random matrix A (before adding the all-ones row)
# m  : total number of equations after augmentation
# q  : field size

n = 20
n1 = 11
m = 12
q = 47

# Algorithm parameters
k = 4
k1 = 1
k2 = 3

l = 6
r = n - m + k - l

l1 = 3
l2 = l - l1

r1 = 3
r2 = r - r1

# ‚ÄúGuessed/marked‚Äù overlap sizes (Œº‚ÇÅ, Œº‚ÇÇ)
mu1 = 2
mu2 = 2


# ----------------------------------------------------------------------------
# Finite field setup
# ----------------------------------------------------------------------------

F = GF(q)
Field_elt = F.list()
h = [q**i for i in range(k)]
all_indices = list(range(n))


# ----------------------------------------------------------------------------
# Precompute SJT swap sequences
# ----------------------------------------------------------------------------

print("Precomputing SJT swap sequences...")
swap_seq_l1 = compute_sjt_swap_sequence(l1)
swap_seq_r1 = compute_sjt_swap_sequence(r1)
swap_seq_l2 = compute_sjt_swap_sequence(l2)
swap_seq_r2 = compute_sjt_swap_sequence(r2)
print("Precomputation done.")


# ============================================================================
# Statistics counters
# ============================================================================
# Statistics:
# - trials: number of random (Œõ‚ÇÅ, Œõ‚ÇÇ) samples attempted until one matches the planted split
#
# The followings are averaged over all the intermediate constraint R ‚àà ùîΩ_q^{k‚ÇÅ}:
#
# - collision_L1: average number of "raw first-level collisions" encountered while
#                 constructing list L‚ÇÅ
# - collision_L2: average number of "raw first-level collisions" encountered while
#                 constructing list L‚ÇÇ
# - collision_L: average number of "raw collisions" between L‚ÇÅ and L‚ÇÇ
# - size_L1: average number of "filtered first-level candidates" that survive the
#            compatibility test and are inserted into L‚ÇÅ
# - size_L2: average number of "filtered first-level candidates" that survive the
#            compatibility test corresponding to L‚ÇÇ
# - size_L: average number of "filtered collisions" between L‚ÇÅ and L‚ÇÇ



trials = 0
collision_L1 = 0
collision_L2 = 0
collision_L = 0

size_L1 = 0
size_L2 = 0
size_L = 0

iter = 0


# ============================================================================
# Main experimental loop
# ============================================================================

for iteration in range(1, 1001):

    # ------------------------------------------------------------------------
    # Generate random linear system with planted solution
    # ------------------------------------------------------------------------
    # given_A is a random n1 x n matrix over F.
    # Then we compute its rref and derive a planted solution V in a structured way:
    #   - sample the ‚Äúfree‚Äù part v2
    #   - solve for v1 so that the system constraints hold (using the rref structure)
    # Finally, we permute/shuffle coordinates (B = shuffled coordinates of V) to create
    # a PKP instance (given_A, B).

    Given_A = random_matrix(F, n1, n)
    Row_reduced_form = Given_A.rref()

    M_tmp = Row_reduced_form[:, n1:]

    flag = 1
    while flag < n:
        v2 = vector(F, random.sample(list(F), n - n1))
        v1 = -M_tmp * v2
        V = vector(F, list(v1) + list(v2))
        flag = len(set(list(V)))

    planted_solution = vector(F, V)
    B = list(V)

    random.shuffle(B)
    B_set = set(B)

    s1_star = V[m - k : m - k + l]
    s2_star = V[m - k + l :]


    # ------------------------------------------------------------------------
    # Augmented system reduction
    # ------------------------------------------------------------------------

    first_row = matrix(F, 1, n, [1] * n)
    A_tilde = first_row.stack(Given_A)
    Augmented_matrix = A_tilde.augment(A_tilde * V)
    RREF_Augment = Augmented_matrix.rref()

    N = RREF_Augment[:, :n]
    t = vector(F, [RREF_Augment[i][n] for i in range(m)])

    _M = N[: m - k, m - k :]
    t1 = t[: m - k]

    while True:
        Q = random_matrix(F, k, k)
        if Q.det() != 0:
            break

    M = Q * N[m - k :, m - k :]
    t2 = Q * t[m - k :]


    # ------------------------------------------------------------------------
    # Block decomposition 
    # ------------------------------------------------------------------------

    U_M = M[:k2, :]
    M1_2 = U_M[:, :l]
    M2_2 = U_M[:, l:]

    L_M = M[k2:, :]
    M11 = L_M[:, :l1]
    M12 = L_M[:, l1 : l1 + l2]
    M21 = L_M[:, l1 + l2 : l1 + l2 + r1]
    M22 = L_M[:, l1 + l2 + r1 :]

    t2_2 = t2[:k2]
    t2_1 = t2[k2:]


    # ------------------------------------------------------------------------
    # Random compatible supports Œõ‚ÇÅ, Œõ‚ÇÇ consistent with planted solution
    # ------------------------------------------------------------------------
    #
    # Choose two random sets of VALUES from B:
    #   LMD1 of size mu1 and LMD2 of size mu2
    # Repeat until those chosen values indeed lie in the planted split
    # (LMD1 ‚äÜ s1_star and LMD2 ‚äÜ s2_star).

    while True:
        trials += 1

        LMD1 = set(random.sample(B, mu1))
        LMD2 = set(random.sample(list(B_set - LMD1), mu2))

        if LMD1.issubset(set(s1_star)) and LMD2.issubset(set(s2_star)):
            break

    LMD1 = {B.index(a) for a in LMD1}
    LMD2 = {B.index(a) for a in LMD2}
    LMD = LMD1 | LMD2

    complement = set(all_indices) - LMD

    sol_lst = []


    # =========================================================================
    # Schroeppel‚ÄìShamir enumeration over R ‚àà ùîΩ_q^{k‚ÇÅ}
    # =========================================================================

    for R in cartesian_product([Field_elt] * k1):

        iter += 1
        R = vector(F, list(R))


        # =====================================================================
        # First-level meet-in-the-middle (construction of L‚ÇÅ)
        # =====================================================================

        L1 = defaultdict(list)

        for i in range(max(0, mu1 - l2), min(mu1, l1) + 1):

            for LMD11 in Subsets(LMD1, i):

                LMD11 = set(LMD11)
                LMD12 = LMD1 - LMD11

                LMD11 = list(LMD11)
                LMD12 = list(LMD12)

                L11 = defaultdict(list)


                # -------------------------------------------------------------
                # Enumerate s‚ÇÅ‚ÇÅ using SJT
                # -------------------------------------------------------------

                for s in Subsets(complement, l1 - i):

                    perm = sorted(list(s) + LMD11)
                    collection = perm[:]

                    w_i = M11 * vector(F, [B[idx] for idx in perm])
                    y = sum(int(w_i[j]) * h[j] for j in range(k1))
                    L11[y].append(perm[:])
                    
                    # Precompute incremental swap vectors:
                    # For a swap at position j (swapping entries u and v in perm),
                    # the change in w_i is:
                    #    Œî = (u_value - v_value) * (M1.col(j) - M1.col(j+1)).
                    #
                    # Here keys are (u_value, v_value, j) storing that Œî.

                    precompute = {
                        (B[u], B[v], j): (B[u] - B[v])
                        * (M11.column(j) - M11.column(j + 1))
                        for u in collection
                        for v in collection
                        for j in range(l1 - 1)
                    }
                    
                    # Apply SJT swaps
                    # Each swap updates perm and w_i incrementally
                    for swap_pos in swap_seq_l1:
                        a, b = perm[swap_pos], perm[swap_pos + 1]
                        perm[swap_pos], perm[swap_pos + 1] = b, a

                        w_i += precompute[(B[b], B[a], swap_pos)]
                        y = sum(int(w_i[j]) * h[j] for j in range(k1))
                        L11[y].append(perm[:])


                # -------------------------------------------------------------
                # Enumerate s‚ÇÅ‚ÇÇ and form L‚ÇÅ via collisions
                # -------------------------------------------------------------

                for s in Subsets(complement, l2 - (mu1 - i)):

                    perm = sorted(list(s) + LMD12)
                    idx_s12 = perm[:]

                    w_i = R - M12 * vector(F, [B[idx] for idx in perm])
                    y = sum(int(w_i[j]) * h[j] for j in range(k1))

                    if L11[y]:
                        collision_L1 += len(L11[y])

                        for idx_s11 in L11[y]:
                            if not set(idx_s11) & set(idx_s12):
                                size_L1 += 1

                                idx_s1 = list(idx_s11) + list(idx_s12)
                                s1 = [B[elt] for elt in idx_s1]

                                x = M1_2 * vector(F, s1)
                                y1 = sum(int(x[j]) * h[j] for j in range(k2))
                                L1[y1].append(idx_s1)

                    precompute = {
                            (B[u], B[v], j): (B[u] - B[v]) * (M12.column(j) - M12.column(j + 1))
                            for u in idx_s12
                            for v in idx_s12
                            for j in range(l2 - 1)
                                }
                            
                    for swap_pos in swap_seq_l2:
                        a, b = perm[swap_pos], perm[swap_pos + 1]
                        perm[swap_pos], perm[swap_pos + 1] = b, a
                
                        w_i -= precompute[(B[b], B[a], swap_pos)]
                        y = sum(int(w_i[j]) * h[j] for j in range(k1))
                
                        if L11[y]:
                            collision_L1 += len(L11[y])
                
                            for idx_s11 in L11[y]:
                                if not set(idx_s11) & set(perm):
                                    size_L1 += 1
                                    idx_s1 = list(idx_s11) + list(perm)
                                    s1 = [B[elt] for elt in idx_s1]
                
                                    x = M1_2 * vector(F, s1)
                                    y1 = sum(int(x[j]) * h[j] for j in range(k2))
                                    L1[y1].append(idx_s1)


        # =====================================================================
        # Second-level meet-in-the-middle (recovery of full solutions)
        # =====================================================================

        for i in range(max(0, mu2 - r2), min(mu2, r1) + 1):

            for LMD21 in Subsets(LMD2, i):

                LMD21 = set(LMD21)
                LMD22 = LMD2 - LMD21

                LMD21 = list(LMD21)
                LMD22 = list(LMD22)

                L21 = defaultdict(list)


                # -------------------------------------------------------------
                # Enumerate s‚ÇÇ‚ÇÅ using SJT
                # -------------------------------------------------------------

                for s in Subsets(complement, r1 - i):

                    perm = sorted(list(s) + LMD21)
                    collection = perm[:]

                    w_i = M21 * vector(F, [B[idx] for idx in perm])
                    y = sum(int(w_i[j]) * h[j] for j in range(k1))
                    L21[y].append(perm[:])

                    precompute = {
                        (B[u], B[v], j): (B[u] - B[v])
                        * (M21.column(j) - M21.column(j + 1))
                        for u in collection
                        for v in collection
                        for j in range(r1 - 1)
                    }

                    for swap_pos in swap_seq_r1:
                        a, b = perm[swap_pos], perm[swap_pos + 1]
                        perm[swap_pos], perm[swap_pos + 1] = b, a

                        w_i += precompute[(B[b], B[a], swap_pos)]
                        y = sum(int(w_i[j]) * h[j] for j in range(k1))
                        L21[y].append(perm[:])


                # -------------------------------------------------------------
                # Enumerate s‚ÇÇ‚ÇÇ and match with L‚ÇÅ
                # -------------------------------------------------------------

                for s in Subsets(complement, r2 - (mu2 - i)):

                    perm = sorted(list(s) + LMD22)
                    idx_s22 = perm[:]

                    w_i = t2_1 - R - M22 * vector(F, [B[idx] for idx in perm])
                    y = sum(int(w_i[j]) * h[j] for j in range(k1))

                    if L21[y]:
                        collision_L2 += len(L21[y])

                        for idx_s21 in L21[y]:
                            if not set(idx_s21) & set(idx_s22):
                                size_L2 += 1

                                idx_s2 = list(idx_s21) + list(idx_s22)
                                s2 = [B[elt] for elt in idx_s2]

                                x = t2_2 - M2_2 * vector(F, s2)
                                y1 = sum(int(x[j]) * h[j] for j in range(k2))

                                if L1[y1]:
                                    collision_L += len(L1[y1])

                                    for idx_s1 in L1[y1]:
                                        if not set(idx_s1) & set(idx_s2):
                                            size_L += 1

                                            s1 = [B[elt] for elt in idx_s1]
                                            x2 = vector(F, s1 + s2)
                                            x1 = t1 - _M * x2

                                            if set(x1) <= B_set and not set(x1) & set(x2):
                                                sol_lst.append(vector(F, list(x1) + list(x2)))

                    precompute = {
                        (B[u], B[v], j): (B[u] - B[v]) * (M22.column(j) - M22.column(j + 1))
                        for u in idx_s22
                        for v in idx_s22
                        for j in range(r2 - 1)
                    }
                
                    for swap_pos in swap_seq_r2:
                        a, b = perm[swap_pos], perm[swap_pos + 1]
                        perm[swap_pos], perm[swap_pos + 1] = b, a
                
                        w_i -= precompute[(B[b], B[a], swap_pos)]
                        y = sum(int(w_i[j]) * h[j] for j in range(k1))
                
                        if L21[y]:
                            collision_L2 += len(L21[y])
                
                            for idx_s21 in L21[y]:
                                if not set(idx_s21) & set(perm):
                                    size_L2 += 1
                
                                    idx_s2 = list(idx_s21) + list(perm)
                                    s2 = [B[elt] for elt in idx_s2]
                
                                    x = t2_2 - M2_2 * vector(F, s2)
                                    y1 = sum(int(x[j]) * h[j] for j in range(k2))
                
                                    if L1[y1]:
                                        collision_L += len(L1[y1])
                
                                        for idx_s1 in L1[y1]:
                                            if not set(idx_s1) & set(idx_s2):
                                                size_L += 1
                
                                                s1 = [B[elt] for elt in idx_s1]
                                                x2 = vector(F, s1 + s2)
                                                x1 = t1 - _M * x2
                
                                                if set(x1) <= B_set and not set(x1) & set(x2):
                                                    sol_lst.append(vector(F, list(x1) + list(x2)))
        # --------------------------------------------------------------------
        # progress statistics inside the Schroeppel‚ÄìShamir loop
        # --------------------------------------------------------------------
        # - Print running :
        #     (i) total number of R-values processed so far across all trials,
        #     (ii) average number of "raw first-level collisions" encountered while
        #          constructing list L‚ÇÅ,
        #     (iii) average number of "filtered first-level candidates" that survive the
        #           compatibility test and are inserted into L‚ÇÅ,
        #     (iv) average number of "raw first-level collisions" encountered while
        #          constructing list L‚ÇÇ,
        #     (v) average number of "filtered first-level candidates" that survive the
        #           compatibility test corresponding to L‚ÇÇ,
        #     (vi) average number of "raw collisions" between L‚ÇÅ and L‚ÇÇ,
        #     (vii) average number of "filtered collisions" between L‚ÇÅ and L‚ÇÇ.

        print(
            iter,
            round(collision_L1 / iter, 2),
            round(size_L1 / iter, 2),
            round(collision_L2 / iter, 2),
            round(size_L2 / iter, 2),
            round(collision_L / iter, 2),
            round(size_L / iter, 2),
        )


    # ------------------------------------------------------------------------
    # Final verification for this iteration. After completing the enumeration for 
    # one random PKP instance.
    # ------------------------------------------------------------------------

    if planted_solution not in sol_lst:
        print("sol not found", (solution, sol_lst))
    else:
        print("solution found")

    if len(sol_lst) > 1:
        print("many solutions", len(sol_lst))

    # - Print running :
    #     (i) number of independent random PKP instances tested so far,
    #     (i) average number of repeatition of finding disjoint subsets that 
    #         lie in the planted split,
    #     (ii) average number of "raw first-level collisions" encountered while
    #          constructing list L‚ÇÅ,
    #     (iii) average number of "filtered first-level candidates" that survive the
    #           compatibility test and are inserted into L‚ÇÅ,
    #     (iv) average number of "raw first-level collisions" encountered while
    #          constructing list L‚ÇÇ,
    #     (v) average number of "filtered first-level candidates" that survive the
    #           compatibility test corresponding to L‚ÇÇ,
    #     (vi) average number of "raw collisions" between L‚ÇÅ and L‚ÇÇ,
    #     (vii) average number of "filtered collisions" between L‚ÇÅ and L‚ÇÇ.

    print(
        iteration,
        round(trials / iteration, 3),
        round(collision_L1 / iter, 2),
        round(size_L1 / iter, 2),
        round(collision_L2 / iter, 2),
        round(size_L2 / iter, 2),
        round(collision_L / iter, 2),
        round(size_L / iter, 2),
    )
    print(" ")
